n = 128
Mat Object: 1 MPI processes
  type: seqaij
row 0: (0, 0.68)  (1, 0.16) 
row 1: (0, 0.16)  (1, 0.68)  (2, 0.16) 
row 2: (1, 0.16)  (2, 0.68)  (3, 0.16) 
row 3: (2, 0.16)  (3, 0.68)  (4, 0.16) 
row 4: (3, 0.16)  (4, 0.68)  (5, 0.16) 
row 5: (4, 0.16)  (5, 0.68)  (6, 0.16) 
row 6: (5, 0.16)  (6, 0.68)  (7, 0.16) 
row 7: (6, 0.16)  (7, 0.68)  (8, 0.16) 
row 8: (7, 0.16)  (8, 0.68)  (9, 0.16) 
row 9: (8, 0.16)  (9, 0.68)  (10, 0.16) 
row 10: (9, 0.16)  (10, 0.68)  (11, 0.16) 
row 11: (10, 0.16)  (11, 0.68)  (12, 0.16) 
row 12: (11, 0.16)  (12, 0.68)  (13, 0.16) 
row 13: (12, 0.16)  (13, 0.68)  (14, 0.16) 
row 14: (13, 0.16)  (14, 0.68)  (15, 0.16) 
row 15: (14, 0.16)  (15, 0.68)  (16, 0.16) 
row 16: (15, 0.16)  (16, 0.68)  (17, 0.16) 
row 17: (16, 0.16)  (17, 0.68)  (18, 0.16) 
row 18: (17, 0.16)  (18, 0.68)  (19, 0.16) 
row 19: (18, 0.16)  (19, 0.68)  (20, 0.16) 
row 20: (19, 0.16)  (20, 0.68)  (21, 0.16) 
row 21: (20, 0.16)  (21, 0.68)  (22, 0.16) 
row 22: (21, 0.16)  (22, 0.68)  (23, 0.16) 
row 23: (22, 0.16)  (23, 0.68)  (24, 0.16) 
row 24: (23, 0.16)  (24, 0.68)  (25, 0.16) 
row 25: (24, 0.16)  (25, 0.68)  (26, 0.16) 
row 26: (25, 0.16)  (26, 0.68)  (27, 0.16) 
row 27: (26, 0.16)  (27, 0.68)  (28, 0.16) 
row 28: (27, 0.16)  (28, 0.68)  (29, 0.16) 
row 29: (28, 0.16)  (29, 0.68)  (30, 0.16) 
row 30: (29, 0.16)  (30, 0.68)  (31, 0.16) 
row 31: (30, 0.16)  (31, 0.68)  (32, 0.16) 
row 32: (31, 0.16)  (32, 0.68)  (33, 0.16) 
row 33: (32, 0.16)  (33, 0.68)  (34, 0.16) 
row 34: (33, 0.16)  (34, 0.68)  (35, 0.16) 
row 35: (34, 0.16)  (35, 0.68)  (36, 0.16) 
row 36: (35, 0.16)  (36, 0.68)  (37, 0.16) 
row 37: (36, 0.16)  (37, 0.68)  (38, 0.16) 
row 38: (37, 0.16)  (38, 0.68)  (39, 0.16) 
row 39: (38, 0.16)  (39, 0.68)  (40, 0.16) 
row 40: (39, 0.16)  (40, 0.68)  (41, 0.16) 
row 41: (40, 0.16)  (41, 0.68)  (42, 0.16) 
row 42: (41, 0.16)  (42, 0.68)  (43, 0.16) 
row 43: (42, 0.16)  (43, 0.68)  (44, 0.16) 
row 44: (43, 0.16)  (44, 0.68)  (45, 0.16) 
row 45: (44, 0.16)  (45, 0.68)  (46, 0.16) 
row 46: (45, 0.16)  (46, 0.68)  (47, 0.16) 
row 47: (46, 0.16)  (47, 0.68)  (48, 0.16) 
row 48: (47, 0.16)  (48, 0.68)  (49, 0.16) 
row 49: (48, 0.16)  (49, 0.68)  (50, 0.16) 
row 50: (49, 0.16)  (50, 0.68)  (51, 0.16) 
row 51: (50, 0.16)  (51, 0.68)  (52, 0.16) 
row 52: (51, 0.16)  (52, 0.68)  (53, 0.16) 
row 53: (52, 0.16)  (53, 0.68)  (54, 0.16) 
row 54: (53, 0.16)  (54, 0.68)  (55, 0.16) 
row 55: (54, 0.16)  (55, 0.68)  (56, 0.16) 
row 56: (55, 0.16)  (56, 0.68)  (57, 0.16) 
row 57: (56, 0.16)  (57, 0.68)  (58, 0.16) 
row 58: (57, 0.16)  (58, 0.68)  (59, 0.16) 
row 59: (58, 0.16)  (59, 0.68)  (60, 0.16) 
row 60: (59, 0.16)  (60, 0.68)  (61, 0.16) 
row 61: (60, 0.16)  (61, 0.68)  (62, 0.16) 
row 62: (61, 0.16)  (62, 0.68)  (63, 0.16) 
row 63: (62, 0.16)  (63, 0.68)  (64, 0.16) 
row 64: (63, 0.16)  (64, 0.68)  (65, 0.16) 
row 65: (64, 0.16)  (65, 0.68)  (66, 0.16) 
row 66: (65, 0.16)  (66, 0.68)  (67, 0.16) 
row 67: (66, 0.16)  (67, 0.68)  (68, 0.16) 
row 68: (67, 0.16)  (68, 0.68)  (69, 0.16) 
row 69: (68, 0.16)  (69, 0.68)  (70, 0.16) 
row 70: (69, 0.16)  (70, 0.68)  (71, 0.16) 
row 71: (70, 0.16)  (71, 0.68)  (72, 0.16) 
row 72: (71, 0.16)  (72, 0.68)  (73, 0.16) 
row 73: (72, 0.16)  (73, 0.68)  (74, 0.16) 
row 74: (73, 0.16)  (74, 0.68)  (75, 0.16) 
row 75: (74, 0.16)  (75, 0.68)  (76, 0.16) 
row 76: (75, 0.16)  (76, 0.68)  (77, 0.16) 
row 77: (76, 0.16)  (77, 0.68)  (78, 0.16) 
row 78: (77, 0.16)  (78, 0.68)  (79, 0.16) 
row 79: (78, 0.16)  (79, 0.68)  (80, 0.16) 
row 80: (79, 0.16)  (80, 0.68)  (81, 0.16) 
row 81: (80, 0.16)  (81, 0.68)  (82, 0.16) 
row 82: (81, 0.16)  (82, 0.68)  (83, 0.16) 
row 83: (82, 0.16)  (83, 0.68)  (84, 0.16) 
row 84: (83, 0.16)  (84, 0.68)  (85, 0.16) 
row 85: (84, 0.16)  (85, 0.68)  (86, 0.16) 
row 86: (85, 0.16)  (86, 0.68)  (87, 0.16) 
row 87: (86, 0.16)  (87, 0.68)  (88, 0.16) 
row 88: (87, 0.16)  (88, 0.68)  (89, 0.16) 
row 89: (88, 0.16)  (89, 0.68)  (90, 0.16) 
row 90: (89, 0.16)  (90, 0.68)  (91, 0.16) 
row 91: (90, 0.16)  (91, 0.68)  (92, 0.16) 
row 92: (91, 0.16)  (92, 0.68)  (93, 0.16) 
row 93: (92, 0.16)  (93, 0.68)  (94, 0.16) 
row 94: (93, 0.16)  (94, 0.68)  (95, 0.16) 
row 95: (94, 0.16)  (95, 0.68)  (96, 0.16) 
row 96: (95, 0.16)  (96, 0.68)  (97, 0.16) 
row 97: (96, 0.16)  (97, 0.68)  (98, 0.16) 
row 98: (97, 0.16)  (98, 0.68)  (99, 0.16) 
row 99: (98, 0.16)  (99, 0.68)  (100, 0.16) 
row 100: (99, 0.16)  (100, 0.68)  (101, 0.16) 
row 101: (100, 0.16)  (101, 0.68)  (102, 0.16) 
row 102: (101, 0.16)  (102, 0.68)  (103, 0.16) 
row 103: (102, 0.16)  (103, 0.68)  (104, 0.16) 
row 104: (103, 0.16)  (104, 0.68)  (105, 0.16) 
row 105: (104, 0.16)  (105, 0.68)  (106, 0.16) 
row 106: (105, 0.16)  (106, 0.68)  (107, 0.16) 
row 107: (106, 0.16)  (107, 0.68)  (108, 0.16) 
row 108: (107, 0.16)  (108, 0.68)  (109, 0.16) 
row 109: (108, 0.16)  (109, 0.68)  (110, 0.16) 
row 110: (109, 0.16)  (110, 0.68)  (111, 0.16) 
row 111: (110, 0.16)  (111, 0.68)  (112, 0.16) 
row 112: (111, 0.16)  (112, 0.68)  (113, 0.16) 
row 113: (112, 0.16)  (113, 0.68)  (114, 0.16) 
row 114: (113, 0.16)  (114, 0.68)  (115, 0.16) 
row 115: (114, 0.16)  (115, 0.68)  (116, 0.16) 
row 116: (115, 0.16)  (116, 0.68)  (117, 0.16) 
row 117: (116, 0.16)  (117, 0.68)  (118, 0.16) 
row 118: (117, 0.16)  (118, 0.68)  (119, 0.16) 
row 119: (118, 0.16)  (119, 0.68)  (120, 0.16) 
row 120: (119, 0.16)  (120, 0.68)  (121, 0.16) 
row 121: (120, 0.16)  (121, 0.68)  (122, 0.16) 
row 122: (121, 0.16)  (122, 0.68)  (123, 0.16) 
row 123: (122, 0.16)  (123, 0.68)  (124, 0.16) 
row 124: (123, 0.16)  (124, 0.68)  (125, 0.16) 
row 125: (124, 0.16)  (125, 0.68)  (126, 0.16) 
row 126: (125, 0.16)  (126, 0.68)  (127, 0.16) 
row 127: (126, 0.16)  (127, 0.68)  (128, 0.16) 
row 128: (127, 0.16)  (128, 0.68) 
Vec Object: 1 MPI processes
  type: seq
0.00300114
0.00600052
0.00899635
0.0119869
0.0149703
0.0179449
0.020909
0.0238607
0.0267983
0.0297201
0.0326244
0.0355094
0.0383735
0.041215
0.0440322
0.0468235
0.0495872
0.0523217
0.0550253
0.0576966
0.060334
0.0629358
0.0655007
0.068027
0.0705134
0.0729583
0.0753604
0.0777182
0.0800304
0.0822957
0.0845127
0.0866801
0.0887967
0.0908613
0.0928727
0.0948297
0.0967312
0.0985761
0.100363
0.102092
0.103761
0.105369
0.106916
0.1084
0.109821
0.111177
0.112469
0.113696
0.114856
0.115949
0.116974
0.117932
0.11882
0.119639
0.120389
0.121069
0.121678
0.122216
0.122683
0.123079
0.123403
0.123655
0.123835
0.123943
0.123979
0.123943
0.123835
0.123655
0.123403
0.123079
0.122683
0.122216
0.121678
0.121069
0.120389
0.119639
0.11882
0.117932
0.116974
0.115949
0.114856
0.113696
0.112469
0.111177
0.109821
0.1084
0.106916
0.105369
0.103761
0.102092
0.100363
0.0985761
0.0967312
0.0948297
0.0928727
0.0908613
0.0887967
0.0866801
0.0845127
0.0822957
0.0800304
0.0777182
0.0753604
0.0729583
0.0705134
0.068027
0.0655007
0.0629358
0.060334
0.0576966
0.0550253
0.0523217
0.0495872
0.0468235
0.0440322
0.041215
0.0383735
0.0355094
0.0326244
0.0297201
0.0267983
0.0238607
0.020909
0.0179449
0.0149703
0.0119869
0.00899635
0.00600052
0.00300114
solution = 0.999907
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

./test.out on a  named r01n21 with 1 processor, by mae-fenghl Wed May 25 09:09:20 2022
Using Petsc Release Version 3.16.6, Mar 30, 2022 

                         Max       Max/Min     Avg       Total
Time (sec):           1.514e-02     1.000   1.514e-02
Objects:              5.000e+00     1.000   5.000e+00
Flop:                 9.092e+06     1.000   9.092e+06  9.092e+06
Flop/sec:             6.004e+08     1.000   6.004e+08  6.004e+08
MPI Messages:         0.000e+00     0.000   0.000e+00  0.000e+00
MPI Message Lengths:  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5129e-02  99.9%  9.0920e+06 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

VecView                1 1.0 2.4796e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNorm             8853 1.0 3.1209e-03 1.0 2.28e+06 1.0 0.0e+00 0.0e+00 0.0e+00 21 25  0  0  0  21 25  0  0  0   729
VecScale            8853 1.0 8.8191e-04 1.0 1.14e+06 1.0 0.0e+00 0.0e+00 0.0e+00  6 13  0  0  0   6 13  0  0  0  1295
VecCopy             8853 1.0 8.9216e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  6  0  0  0  0   6  0  0  0  0     0
VecSet                 3 1.0 2.2888e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyBegin       1 1.0 0.0000e+00 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         1 1.0 0.0000e+00 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult             8853 1.0 5.1482e-03 1.0 5.67e+06 1.0 0.0e+00 0.0e+00 0.0e+00 34 62  0  0  0  34 62  0  0  0  1102
MatAssemblyBegin       1 1.0 0.0000e+00 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         1 1.0 4.6015e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatView                1 1.0 9.2006e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  6  0  0  0  0   6  0  0  0  0     0
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Vector     2              2         5312     0.
              Matrix     1              1        13596     0.
              Viewer     2              1          840     0.
========================================================================================================================
Average time to get PetscTime(): 9.53674e-08
#PETSc Option Table entries:
-ksp_atol 1.0e-50
-ksp_converged_reason
-ksp_gmres_modifiedgramschmidt
-ksp_gmres_restart 30
-ksp_max_it 1500
-ksp_monitor_short
-ksp_rtol 1.0e-10
-ksp_type gmres
-ksp_view
-log_view
-pc_type asm
-sub_ksp_type richardson
-sub_pc_type icc
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-mpi-dir=/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64 --with-blaslapack-dir=/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl --with-scalapack-include=/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/include --with-scalapack-lib="-L/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/lib/intel64 -lmkl_blacs_intelmpi_lp64 -lmkl_scalapack_lp64" --with-hdf5-dir=/work/mae-fenghl/lib/hdf5-1.12.1 --with-debugging=no --prefix=/work/mae-fenghl/lib/petsc-3.16.6 --download-hypre=/work/mae-fenghl/HPC/Homework_5/petsc-3.16.6-package/hypre-2.23.0.tar.gz --download-mumps=/work/mae-fenghl/HPC/Homework_5/petsc-3.16.6-package/petsc-pkg-mumps-6d1470374d32.tar.gz --download-metis=/work/mae-fenghl/HPC/Homework_5/petsc-3.16.6-package/petsc-pkg-metis-c8d2dc1e751e.tar.gz COPTFLAGS="-O3 -march=native -mtune=native" CXXOPTFLAGS="-O3 -march=native -mtune=native" FOPTFLAGS="-O3 -march=native -mtune=native"
-----------------------------------------
Libraries compiled on 2022-05-21 07:00:50 on login05 
Machine characteristics: Linux-3.10.0-862.el7.x86_64-x86_64-with-redhat-7.5-Maipo
Using PETSc directory: /work/mae-fenghl/lib/petsc-3.16.6
Using PETSc arch: 
-----------------------------------------

Using C compiler: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -O3 -march=native -mtune=native  -std=c99 
Using Fortran compiler: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -O3 -march=native -mtune=native     -std=c99
-----------------------------------------

Using include paths: -I/work/mae-fenghl/lib/petsc-3.16.6/include -I/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/include -I/work/mae-fenghl/lib/hdf5-1.12.1/include -I/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/include
-----------------------------------------

Using C linker: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpicc
Using Fortran linker: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpif90
Using libraries: -Wl,-rpath,/work/mae-fenghl/lib/petsc-3.16.6/lib -L/work/mae-fenghl/lib/petsc-3.16.6/lib -lpetsc -Wl,-rpath,/work/mae-fenghl/lib/petsc-3.16.6/lib -L/work/mae-fenghl/lib/petsc-3.16.6/lib -L/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/lib/intel64 -Wl,-rpath,/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/lib/intel64 -Wl,-rpath,/work/mae-fenghl/lib/hdf5-1.12.1/lib -L/work/mae-fenghl/lib/hdf5-1.12.1/lib -Wl,-rpath,/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib/release_mt -L/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib/release_mt -Wl,-rpath,/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib -L/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib -Wl,-rpath,/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -L/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib/release_mt -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lmkl_blacs_intelmpi_lp64 -lmkl_scalapack_lp64 -lmkl_intel_lp64 -lmkl_core -lmkl_sequential -lpthread -lhdf5_hl -lhdf5 -lmetis -lm -lX11 -lstdc++ -ldl -lmpifort -lmpi -lmpigi -lrt -lpthread -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lstdc++ -ldl
-----------------------------------------

